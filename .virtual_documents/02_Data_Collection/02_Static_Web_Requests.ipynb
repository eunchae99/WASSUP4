


import requests
from bs4 import BeautifulSoup
import pandas as pd


PATH = 'https://www.melon.com/chart/index.htm'
resp = requests.get(PATH)
resp


resp.text


info = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36'}
info


resp = requests.get(PATH, headers = info)
resp


html_src = resp.text
html_src


soup = BeautifulSoup(html_src, 'lxml')
soup





# 곡이름 찾기
len(soup.select('.ellipsis.rank01 a'))


song = [item.text for item in soup.select('.ellipsis.rank01 a')]
len(song)


title_list =[]
title = soup.select('.ellipsis.rank01 a')
for i in title:
    title_list.append(i.text)
title_list


title= [i.text for i in soup.select('.ellipsis.rank01 a')]
title





# 가수 이름 찾기
len(soup.select('.ellipsis.rank02 a'))


artist = []
for item in soup.select('.ellipsis.rank02>a'):
    artist.append(item.text)
print(len(artist))
print(artist)


len(soup.select('.checkEllipsis'))


name = [item.text for item in soup.select('.checkEllipsis')]
len(name)


# 순위 인덱스 만들기
rank = list((range(1, 101)))
rank


# 판다스로 데이터프레임 만들기 column : data
songDF = pd.DataFrame({ '순위': rank,
              '노래제목': song,
              '가수명': name})
songDF





import requests


param = {'name':'Amy', 'age':20, 'address':'Seoul'}


# get방식
resp1 = requests.get('http://httpbin.org/get', params=param)
print(resp1)


print(resp1.text)


# POST방식
resp2 = requests.post('http://httpbin.org/post', data=param)
print(resp2)


print(resp2.text)





PATH = 'https://search.naver.com/search.naver'
PATH


keyword = input('검색어를 입력하세요 : ')


resp = requests.get(PATH, params={'query':keyword})
resp


html_src = resp.text
html_src





soup = BeautifulSoup(html_src, 'lxml')
soup


result = soup.select('.news_tit')
print(len(result))
print(result)


for a in result:
    print(a.text, a['href'])





import requests
from bs4 import BeautifulSoup


response = requests.get('https://korean.visitkorea.or.kr/')
html_src = response.text


html_src


soup = BeautifulSoup(html_src, 'lxml')
soup


# 인기검색어와 url link까지 추출해보자
result = soup.select('.popular li a')
print(len(result))
print(result)

# 동적 웹페이지라 결과 0
